{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Melio Fullstack Data Scientist Technical Interview\n",
    "\n",
    "### Task 1: Building the classifier\n",
    "\n",
    "This is the main data science component of the technical assessment.\n",
    "\n",
    "Build a classifier to determine whether the name belongs to a `Person`, `Company`, or `University`:\n",
    "\n",
    "  - You can use any library you want.\n",
    "  - You can use a rule-based classification, a pre-built model/embedding, build a model yourself or a hybrid. \n",
    "  - Format:\n",
    "    - If you are building an ML solution, the training of your model can be in a Jupyter notebook. \n",
    "    - If you are not building an ML solution, you will have to embed your python code into the app.\n",
    "\n",
    "Note that the classifications are generated by the client's upstream system, but it is not always correct. \n",
    "\n",
    "## Submission Requirements\n",
    "\n",
    "  1. Give enough information on how to run your solution (i.e. python version, packages, requirements.txt, Dockerfile, etc.).\n",
    "  2. State all of your assumptions, if any.\n",
    "  3. There is no right or wrong answer, but give a clear reasoning on each step you took. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dirty_name</th>\n",
       "      <th>dirty_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3799</th>\n",
       "      <td>SIPHOKAZI OBERHOLZER</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3866</th>\n",
       "      <td>Kori Growcock</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>NADEAN COCKERILL</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>rev. anna mlambo</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>nomfundo ngubane</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4123</th>\n",
       "      <td>deny gallihawk</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1356</th>\n",
       "      <td>MYMM  skaboo voonyx Photospace inc.</td>\n",
       "      <td>Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453</th>\n",
       "      <td>Elvina Buchett</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874</th>\n",
       "      <td>DR. BARRY ZUMA</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2316</th>\n",
       "      <td>CHESTON ARISS</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               dirty_name dirty_label\n",
       "3799                 SIPHOKAZI OBERHOLZER      Person\n",
       "3866                        Kori Growcock      Person\n",
       "992                      NADEAN COCKERILL      Person\n",
       "725                      rev. anna mlambo      Person\n",
       "113                      nomfundo ngubane      Person\n",
       "4123                       deny gallihawk      Person\n",
       "1356  MYMM  skaboo voonyx Photospace inc.     Company\n",
       "1453                       Elvina Buchett      Person\n",
       "1874                       DR. BARRY ZUMA      Person\n",
       "2316                        CHESTON ARISS      Person"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('names_data_candidate.csv')\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1b82be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import string\n",
    "import unidecode\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d613d993",
   "metadata": {},
   "source": [
    "# Data Exploration  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d901cf8",
   "metadata": {},
   "source": [
    "## First remove all accents, capitals and punctuation to create cleaner data to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c895516",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowercase_names(df):\n",
    "    \"\"\"\n",
    "    Converts all entries in the 'dirty_name' column to lowercase.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas.DataFrame\n",
    "        Input DataFrame with a 'dirty_name' column.\n",
    "\n",
    "    Returns:\n",
    "    - df: pandas.DataFrame\n",
    "        DataFrame with 'dirty_name' values converted to lowercase.\n",
    "\n",
    "    This step standardises casing to avoid case-sensitive mismatches in rule-based\n",
    "    keyword matching and improves model generalisation.\n",
    "    \"\"\"\n",
    "    df['dirty_name'] = df['dirty_name'].str.lower()\n",
    "    return df\n",
    "\n",
    "def remove_punctuation(df):\n",
    "    \"\"\"\n",
    "    Removes punctuation characters from the 'dirty_name' column.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas.DataFrame\n",
    "        Input DataFrame with a 'dirty_name' column.\n",
    "\n",
    "    Returns:\n",
    "    - df: pandas.DataFrame\n",
    "        DataFrame with punctuation removed from 'dirty_name'.\n",
    "\n",
    "    This reduces noise from characters like '.', ',', etc., which can vary in presence\n",
    "    but rarely carry class-discriminative value.\n",
    "    \"\"\"\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    df['dirty_name'] = df['dirty_name'].apply(lambda name: name.translate(translator))\n",
    "    return df\n",
    "\n",
    "\n",
    "def remove_accents(df):\n",
    "    \"\"\"\n",
    "    Replaces accented characters in the 'dirty_name' column with ASCII equivalents.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas.DataFrame\n",
    "        Input DataFrame with a 'dirty_name' column.\n",
    "\n",
    "    Returns:\n",
    "    - df: pandas.DataFrame\n",
    "        DataFrame with special/accented characters replaced.\n",
    "\n",
    "    This improves matching for names with diacritics (e.g. 'Émile' → 'Emile').\n",
    "    \"\"\"\n",
    "    df['dirty_name'] = df['dirty_name'].apply(unidecode.unidecode)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bc66383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       dirty_name dirty_label\n",
      "0                  wright pentlow      Person\n",
      "1                ms sydney hadebe      Person\n",
      "2             prof hennie vorster      Person\n",
      "3                   enrica hayter      Person\n",
      "4                    teboho ngema      Person\n",
      "5                    irene klaves      Person\n",
      "6                   aila tenpenny      Person\n",
      "7            oceanne dawidowitsch      Person\n",
      "8                 long mac geffen      Person\n",
      "9                thabiso blignaut      Person\n",
      "10              emalee le strange      Person\n",
      "11                 lindiwe wright      Person\n",
      "12  imibono fuels capital pty ltd     Company\n",
      "13          imibono fuels pty ltd     Company\n",
      "14                  imibono fuels     Company\n",
      "15          mr miss bronwyn kotze      Person\n",
      "16            dr anson dudderidge      Person\n",
      "17          prof frederick turner     Company\n",
      "18               katherina hawkey      Person\n",
      "19        dr rev hannes mashinini      Person\n"
     ]
    }
   ],
   "source": [
    "df = lowercase_names(df)\n",
    "df = remove_punctuation(df)\n",
    "df = remove_accents(df)\n",
    "print(df.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a09222",
   "metadata": {},
   "source": [
    "## remove known miss labelled instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "688277dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify noisy labels\n",
    "def identify_noisy_labels(df):\n",
    "    \"\"\"\n",
    "    Identifies and counts noisy or invalid labels in the classification dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas.DataFrame\n",
    "        Input DataFrame containing at least 'dirty_label' column.\n",
    "\n",
    "    Returns:\n",
    "    - noisy_df: pandas.DataFrame\n",
    "        Subset of rows with invalid labels.\n",
    "    - num_noisy: int\n",
    "        Count of noisy label rows.\n",
    "\n",
    "    This function compares all entries in the 'dirty_label' column against a known set\n",
    "    of valid classes ('Person', 'Company', 'University'). Any entry not matching these\n",
    "    is considered noisy.\n",
    "    \"\"\"\n",
    "    valid_labels = {'Person', 'Company', 'University'}\n",
    "\n",
    "    # Filter out rows that don't match the valid label set\n",
    "    noisy_df = df[~df['dirty_label'].isin(valid_labels)]\n",
    "    num_noisy = len(noisy_df)\n",
    "\n",
    "    print(f\"Number of noisy label entries: {num_noisy}\")\n",
    "    return noisy_df, num_noisy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7214eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of noisy label entries: 0\n"
     ]
    }
   ],
   "source": [
    "noisy_df, num_noisy = identify_noisy_labels(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b46c7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no entries are missing classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2de62554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for miss classifcations using a rule based approach\n",
    "\n",
    "def get_label_patterns():\n",
    "    \"\"\"\n",
    "    Defines common indicative substrings or patterns for each label class.\n",
    "    \n",
    "    Returns:\n",
    "    - patterns: dict\n",
    "        A dictionary with keys as class labels ('Person', 'Company', 'University') and\n",
    "        values as lists of lowercase keywords typically found in those categories.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'Person': [\n",
    "            'mr', 'mrs', 'ms', 'miss', 'dr', 'prof', 'rev', 'sr'\n",
    "        ],\n",
    "        'Company': [\n",
    "            'pty', 'ltd', 'inc', 'cc', 'corp', 'company', 'llc', 'gmbh', 'foundation', 'trust',\n",
    "            'capital', 'group', 'holdings', 'investments'\n",
    "        ],\n",
    "        'University': [\n",
    "            'university', 'college', 'institute', 'politecnico', 'instituto', 'universidad', 'universidade', 'universite'\n",
    "        ]\n",
    "    }\n",
    "\n",
    "def flag_misclassified_entries(df):\n",
    "    \"\"\"\n",
    "    Identifies rows where the label seems to contradict common naming patterns.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas.DataFrame\n",
    "        DataFrame with 'dirty_name' and 'dirty_label' columns.\n",
    "\n",
    "    Returns:\n",
    "    - mismatched_df: pandas.DataFrame\n",
    "        Subset of rows suspected to be misclassified based on rule-based patterns.\n",
    "    - num_mismatches: int\n",
    "        Count of suspected misclassifications.\n",
    "\n",
    "    This function uses common keyword patterns for each class and flags entries\n",
    "    where the name suggests one class, but the label is something else.\n",
    "    \"\"\"\n",
    "    patterns = get_label_patterns()\n",
    "    \n",
    "    # Precompile regex patterns for efficiency\n",
    "    compiled_patterns = {\n",
    "        label: re.compile('|'.join([fr'\\b{re.escape(p)}\\b' for p in keywords]), re.IGNORECASE)\n",
    "        for label, keywords in patterns.items()\n",
    "    }\n",
    "\n",
    "    mismatches = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        name = row['dirty_name']\n",
    "        label = row['dirty_label']\n",
    "        \n",
    "        # Determine expected label(s) based on pattern match\n",
    "        expected_labels = [lbl for lbl, pat in compiled_patterns.items() if pat.search(name)]\n",
    "        \n",
    "        # If the actual label is not one of the expected ones, flag as mismatch\n",
    "        if expected_labels and label not in expected_labels:\n",
    "            mismatches.append(row)\n",
    "\n",
    "    mismatched_df = pd.DataFrame(mismatches)\n",
    "    num_mismatches = len(mismatched_df)\n",
    "\n",
    "    print(f\"Number of suspected misclassified rows: {num_mismatches}\")\n",
    "    return mismatched_df, num_mismatches\n",
    "\n",
    "def clean_misclassified_entries(df):\n",
    "    \"\"\"\n",
    "    Removes suspected misclassified rows from the dataset based on naming patterns.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas.DataFrame\n",
    "        Original dataset.\n",
    "\n",
    "    Returns:\n",
    "    - cleaned_df: pandas.DataFrame\n",
    "        Dataset with suspected misclassified rows removed.\n",
    "\n",
    "    This function uses the rule-based flagging logic to detect and exclude entries\n",
    "    that appear to have incorrect labels.\n",
    "    \"\"\"\n",
    "    mismatched_df, _ = flag_misclassified_entries(df)\n",
    "    \n",
    "    # Remove mismatched entries\n",
    "    cleaned_df = df.drop(mismatched_df.index).reset_index(drop=True)\n",
    "    print(f\"Cleaned dataset size after removing misclassified rows: {len(cleaned_df)}\")\n",
    "\n",
    "    return cleaned_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3471a353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of suspected misclassified rows: 84\n",
      "Number of suspected misclassified rows: 84\n",
      "Cleaned dataset size after removing misclassified rows: 4436\n"
     ]
    }
   ],
   "source": [
    "# get the label patterns\n",
    "label_patterns = get_label_patterns()\n",
    "# flag the missclassified entries and print the number (check its not too high)\n",
    "mismatched_df, num_mismatches = flag_misclassified_entries(df)\n",
    "# happy it is not too many, so remove the bad ones\n",
    "df = clean_misclassified_entries(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6680cf3d",
   "metadata": {},
   "source": [
    "## Remove doubled prefixes for names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfe2b3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_double_prefixes(df):\n",
    "    \"\"\"\n",
    "    Removes the first two words in 'dirty_name' if both are common prefixes\n",
    "    (e.g., 'Mr Dr Jane Doe' → 'Jane Doe').\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas.DataFrame\n",
    "        Input DataFrame with a 'dirty_name' column (pre-cleaned, lowercase, no punctuation).\n",
    "\n",
    "    Returns:\n",
    "    - df: pandas.DataFrame\n",
    "        DataFrame with modified 'dirty_name' values where double prefixes were removed.\n",
    "\n",
    "    This function targets cases where two known titles/prefixes occur at the beginning of the name.\n",
    "    It uses a defined prefix list and only alters names that start with two such prefixes.\n",
    "    \"\"\"\n",
    "    # Define common person prefixes\n",
    "    prefixes = {'mr', 'mrs', 'ms', 'miss', 'dr', 'prof', 'rev', 'sr'}\n",
    "\n",
    "    def clean_name(name):\n",
    "        # Split name into parts\n",
    "        parts = name.strip().split()\n",
    "\n",
    "        # Check if first two words are both valid prefixes\n",
    "        if len(parts) >= 2 and parts[0] in prefixes and parts[1] in prefixes:\n",
    "            return ' '.join(parts[2:])  # Remove both\n",
    "        return name\n",
    "\n",
    "    df['dirty_name'] = df['dirty_name'].apply(clean_name)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9532ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = remove_double_prefixes(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43ff713",
   "metadata": {},
   "source": [
    "## Count the number of entries for each category and spread of patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1bae86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_all_patterns_by_label(df, pattern_dict):\n",
    "    \"\"\"\n",
    "    Counts how often each pattern from a label-specific pattern dictionary appears\n",
    "    in the corresponding names within each label group, and includes the total number\n",
    "    of entries per group.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas.DataFrame\n",
    "        DataFrame with 'dirty_name' and 'dirty_label' columns.\n",
    "    - pattern_dict: dict\n",
    "        Dictionary where keys are label names (e.g., 'Person', 'Company') and values are\n",
    "        lists of lowercase patterns to match.\n",
    "\n",
    "    Returns:\n",
    "    - results: dict\n",
    "        A nested dictionary where each key is a label, and the value is another dictionary\n",
    "        containing:\n",
    "            - pattern counts (including 'no_pattern')\n",
    "            - 'total_entries': total number of rows for that label\n",
    "\n",
    "    This function gives insight into how many names match each pattern and the pattern\n",
    "    coverage relative to total entries per category.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    for label, patterns in pattern_dict.items():\n",
    "        label_df = df[df['dirty_label'] == label]\n",
    "        total = len(label_df)\n",
    "\n",
    "        pattern_counts = {p: 0 for p in patterns}\n",
    "        pattern_counts['no_pattern'] = 0\n",
    "        pattern_counts['total_entries'] = total\n",
    "\n",
    "        for name in label_df['dirty_name']:\n",
    "            found = False\n",
    "            for p in patterns:\n",
    "                if p in name:\n",
    "                    pattern_counts[p] += 1\n",
    "                    found = True\n",
    "            if not found:\n",
    "                pattern_counts['no_pattern'] += 1\n",
    "\n",
    "        print(f\"\\nPattern match counts for label: '{label}'\")\n",
    "        print(f\"Total entries: {total}\")\n",
    "        for k, v in pattern_counts.items():\n",
    "            if k != 'total_entries':\n",
    "                print(f\"{k}: {v}\")\n",
    "        \n",
    "        results[label] = pattern_counts\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2b5b2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pattern match counts for label: 'Person'\n",
      "Total entries: 3674\n",
      "mr: 364\n",
      "mrs: 171\n",
      "ms: 121\n",
      "miss: 230\n",
      "dr: 372\n",
      "prof: 119\n",
      "rev: 69\n",
      "sr: 55\n",
      "no_pattern: 2383\n",
      "\n",
      "Pattern match counts for label: 'Company'\n",
      "Total entries: 664\n",
      "pty: 96\n",
      "ltd: 128\n",
      "inc: 25\n",
      "cc: 54\n",
      "corp: 25\n",
      "company: 11\n",
      "llc: 15\n",
      "gmbh: 21\n",
      "foundation: 4\n",
      "trust: 18\n",
      "capital: 6\n",
      "group: 12\n",
      "enterprises: 0\n",
      "holdings: 4\n",
      "investments: 6\n",
      "no_pattern: 348\n",
      "\n",
      "Pattern match counts for label: 'University'\n",
      "Total entries: 98\n",
      "university: 58\n",
      "college: 14\n",
      "institute: 2\n",
      "technikon: 0\n",
      "polytechnic: 0\n",
      "school of: 1\n",
      "politecnico: 2\n",
      "instituto: 3\n",
      "universidad: 15\n",
      "universidade: 2\n",
      "universite: 2\n",
      "no_pattern: 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Person': {'mr': 364,\n",
       "  'mrs': 171,\n",
       "  'ms': 121,\n",
       "  'miss': 230,\n",
       "  'dr': 372,\n",
       "  'prof': 119,\n",
       "  'rev': 69,\n",
       "  'sr': 55,\n",
       "  'no_pattern': 2383,\n",
       "  'total_entries': 3674},\n",
       " 'Company': {'pty': 96,\n",
       "  'ltd': 128,\n",
       "  'inc': 25,\n",
       "  'cc': 54,\n",
       "  'corp': 25,\n",
       "  'company': 11,\n",
       "  'llc': 15,\n",
       "  'gmbh': 21,\n",
       "  'foundation': 4,\n",
       "  'trust': 18,\n",
       "  'capital': 6,\n",
       "  'group': 12,\n",
       "  'enterprises': 0,\n",
       "  'holdings': 4,\n",
       "  'investments': 6,\n",
       "  'no_pattern': 348,\n",
       "  'total_entries': 664},\n",
       " 'University': {'university': 58,\n",
       "  'college': 14,\n",
       "  'institute': 2,\n",
       "  'technikon': 0,\n",
       "  'polytechnic': 0,\n",
       "  'school of': 1,\n",
       "  'politecnico': 2,\n",
       "  'instituto': 3,\n",
       "  'universidad': 15,\n",
       "  'universidade': 2,\n",
       "  'universite': 2,\n",
       "  'no_pattern': 6,\n",
       "  'total_entries': 98}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_all_patterns_by_label(df, get_label_patterns())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7679aa5c",
   "metadata": {},
   "source": [
    "Suggested augmentation is add common words at random during training for even split of them.\n",
    "Also need to ensure data split is even when training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c805b824",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Melio_name_classifier_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
