{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Melio Fullstack Data Scientist Technical Interview\n",
    "\n",
    "### Task 1: Building the classifier\n",
    "\n",
    "This is the main data science component of the technical assessment.\n",
    "\n",
    "Build a classifier to determine whether the name belongs to a `Person`, `Company`, or `University`:\n",
    "\n",
    "  - You can use any library you want.\n",
    "  - You can use a rule-based classification, a pre-built model/embedding, build a model yourself or a hybrid. \n",
    "  - Format:\n",
    "    - If you are building an ML solution, the training of your model can be in a Jupyter notebook. \n",
    "    - If you are not building an ML solution, you will have to embed your python code into the app.\n",
    "\n",
    "Note that the classifications are generated by the client's upstream system, but it is not always correct. \n",
    "\n",
    "## Submission Requirements\n",
    "\n",
    "  1. Give enough information on how to run your solution (i.e. python version, packages, requirements.txt, Dockerfile, etc.).\n",
    "  2. State all of your assumptions, if any.\n",
    "  3. There is no right or wrong answer, but give a clear reasoning on each step you took. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5911da45",
   "metadata": {},
   "source": [
    "# ! Please see README for assumptions and project planning process !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dirty_name</th>\n",
       "      <th>dirty_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2982</th>\n",
       "      <td>DR nomfundo buthelezi</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wright Pentlow</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3106</th>\n",
       "      <td>rev. bryan edwards</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2289</th>\n",
       "      <td>Sr. dr. stephen viljoen</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>MISS KABELO MAZIBUKO</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4242</th>\n",
       "      <td>MRS heidi mngomezulu</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2739</th>\n",
       "      <td>Altusi Group Ltd</td>\n",
       "      <td>Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>Miss Tracy Coetzer</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3597</th>\n",
       "      <td>Judicaël Deware</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3799</th>\n",
       "      <td>SIPHOKAZI OBERHOLZER</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   dirty_name dirty_label\n",
       "2982    DR nomfundo buthelezi      Person\n",
       "0              Wright Pentlow      Person\n",
       "3106       rev. bryan edwards      Person\n",
       "2289  Sr. dr. stephen viljoen      Person\n",
       "947      MISS KABELO MAZIBUKO      Person\n",
       "4242     MRS heidi mngomezulu      Person\n",
       "2739         Altusi Group Ltd     Company\n",
       "1152       Miss Tracy Coetzer      Person\n",
       "3597          Judicaël Deware      Person\n",
       "3799     SIPHOKAZI OBERHOLZER      Person"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('names_data_candidate.csv')\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c1b82be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import string\n",
    "import unidecode\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, confusion_matrix, log_loss, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from joblib import dump\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d613d993",
   "metadata": {},
   "source": [
    "# Data Exploration  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d901cf8",
   "metadata": {},
   "source": [
    "## First remove all accents, capitals and punctuation to create cleaner data to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c895516",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowercase_names(df):\n",
    "    \"\"\"\n",
    "    Converts all entries in the 'dirty_name' column to lowercase.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas.DataFrame\n",
    "        Input DataFrame with a 'dirty_name' column.\n",
    "\n",
    "    Returns:\n",
    "    - df: pandas.DataFrame\n",
    "        DataFrame with 'dirty_name' values converted to lowercase.\n",
    "\n",
    "    This step standardises casing to avoid case-sensitive mismatches in rule-based\n",
    "    keyword matching and improves model generalisation.\n",
    "    \"\"\"\n",
    "    df['dirty_name'] = df['dirty_name'].str.lower()\n",
    "    return df\n",
    "\n",
    "def remove_punctuation(df):\n",
    "    \"\"\"\n",
    "    Removes punctuation characters from the 'dirty_name' column.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas.DataFrame\n",
    "        Input DataFrame with a 'dirty_name' column.\n",
    "\n",
    "    Returns:\n",
    "    - df: pandas.DataFrame\n",
    "        DataFrame with punctuation removed from 'dirty_name'.\n",
    "\n",
    "    This reduces noise from characters like '.', ',', etc., which can vary in presence\n",
    "    but rarely carry class-discriminative value.\n",
    "    \"\"\"\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    df['dirty_name'] = df['dirty_name'].apply(lambda name: name.translate(translator))\n",
    "    return df\n",
    "\n",
    "\n",
    "def remove_accents(df):\n",
    "    \"\"\"\n",
    "    Replaces accented characters in the 'dirty_name' column with ASCII equivalents.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas.DataFrame\n",
    "        Input DataFrame with a 'dirty_name' column.\n",
    "\n",
    "    Returns:\n",
    "    - df: pandas.DataFrame\n",
    "        DataFrame with special/accented characters replaced.\n",
    "\n",
    "    This improves matching for names with diacritics (e.g. 'Émile' → 'Emile').\n",
    "    \"\"\"\n",
    "    df['dirty_name'] = df['dirty_name'].apply(unidecode.unidecode)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bc66383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       dirty_name dirty_label\n",
      "0                  wright pentlow      Person\n",
      "1                ms sydney hadebe      Person\n",
      "2             prof hennie vorster      Person\n",
      "3                   enrica hayter      Person\n",
      "4                    teboho ngema      Person\n",
      "5                    irene klaves      Person\n",
      "6                   aila tenpenny      Person\n",
      "7            oceanne dawidowitsch      Person\n",
      "8                 long mac geffen      Person\n",
      "9                thabiso blignaut      Person\n",
      "10              emalee le strange      Person\n",
      "11                 lindiwe wright      Person\n",
      "12  imibono fuels capital pty ltd     Company\n",
      "13          imibono fuels pty ltd     Company\n",
      "14                  imibono fuels     Company\n",
      "15          mr miss bronwyn kotze      Person\n",
      "16            dr anson dudderidge      Person\n",
      "17          prof frederick turner     Company\n",
      "18               katherina hawkey      Person\n",
      "19        dr rev hannes mashinini      Person\n"
     ]
    }
   ],
   "source": [
    "df = lowercase_names(df)\n",
    "df = remove_punctuation(df)\n",
    "df = remove_accents(df)\n",
    "print(df.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a09222",
   "metadata": {},
   "source": [
    "## remove known miss labelled instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "688277dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify noisy labels\n",
    "def identify_noisy_labels(df):\n",
    "    \"\"\"\n",
    "    Identifies and counts noisy or invalid labels in the classification dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas.DataFrame\n",
    "        Input DataFrame containing at least 'dirty_label' column.\n",
    "\n",
    "    Returns:\n",
    "    - noisy_df: pandas.DataFrame\n",
    "        Subset of rows with invalid labels.\n",
    "    - num_noisy: int\n",
    "        Count of noisy label rows.\n",
    "\n",
    "    This function compares all entries in the 'dirty_label' column against a known set\n",
    "    of valid classes ('Person', 'Company', 'University'). Any entry not matching these\n",
    "    is considered noisy.\n",
    "    \"\"\"\n",
    "    valid_labels = {'Person', 'Company', 'University'}\n",
    "\n",
    "    # Filter out rows that don't match the valid label set\n",
    "    noisy_df = df[~df['dirty_label'].isin(valid_labels)]\n",
    "    num_noisy = len(noisy_df)\n",
    "\n",
    "    print(f\"Number of noisy label entries: {num_noisy}\")\n",
    "    return noisy_df, num_noisy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7214eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of noisy label entries: 0\n"
     ]
    }
   ],
   "source": [
    "noisy_df, num_noisy = identify_noisy_labels(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b46c7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no entries are missing classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2de62554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for miss classifcations using a rule based approach\n",
    "\n",
    "def get_label_patterns():\n",
    "    \"\"\"\n",
    "    Defines common indicative substrings or patterns for each label class.\n",
    "    \n",
    "    Returns:\n",
    "    - patterns: dict\n",
    "        A dictionary with keys as class labels ('Person', 'Company', 'University') and\n",
    "        values as lists of lowercase keywords typically found in those categories.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'Person': [\n",
    "            'mr', 'mrs', 'ms', 'miss', 'dr', 'prof', 'rev', 'sr'\n",
    "        ],\n",
    "        'Company': [\n",
    "            'pty', 'ltd', 'inc', 'cc', 'corp', 'company', 'llc', 'gmbh', 'foundation', 'trust',\n",
    "            'capital', 'group', 'holdings', 'investments'\n",
    "        ],\n",
    "        'University': [\n",
    "            'university', 'college', 'institute', 'politecnico', 'instituto', 'universidad', 'universidade', 'universite'\n",
    "        ]\n",
    "    }\n",
    "\n",
    "def flag_misclassified_entries(df):\n",
    "    \"\"\"\n",
    "    Identifies rows where the label seems to contradict common naming patterns.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas.DataFrame\n",
    "        DataFrame with 'dirty_name' and 'dirty_label' columns.\n",
    "\n",
    "    Returns:\n",
    "    - mismatched_df: pandas.DataFrame\n",
    "        Subset of rows suspected to be misclassified based on rule-based patterns.\n",
    "    - num_mismatches: int\n",
    "        Count of suspected misclassifications.\n",
    "\n",
    "    This function uses common keyword patterns for each class and flags entries\n",
    "    where the name suggests one class, but the label is something else.\n",
    "    \"\"\"\n",
    "    patterns = get_label_patterns()\n",
    "    \n",
    "    # Precompile regex patterns for efficiency\n",
    "    compiled_patterns = {\n",
    "        label: re.compile('|'.join([fr'\\b{re.escape(p)}\\b' for p in keywords]), re.IGNORECASE)\n",
    "        for label, keywords in patterns.items()\n",
    "    }\n",
    "\n",
    "    mismatches = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        name = row['dirty_name']\n",
    "        label = row['dirty_label']\n",
    "        \n",
    "        # Determine expected label(s) based on pattern match\n",
    "        expected_labels = [lbl for lbl, pat in compiled_patterns.items() if pat.search(name)]\n",
    "        \n",
    "        # If the actual label is not one of the expected ones, flag as mismatch\n",
    "        if expected_labels and label not in expected_labels:\n",
    "            mismatches.append(row)\n",
    "\n",
    "    mismatched_df = pd.DataFrame(mismatches)\n",
    "    num_mismatches = len(mismatched_df)\n",
    "\n",
    "    print(f\"Number of suspected misclassified rows: {num_mismatches}\")\n",
    "    return mismatched_df, num_mismatches\n",
    "\n",
    "def clean_misclassified_entries(df):\n",
    "    \"\"\"\n",
    "    Removes suspected misclassified rows from the dataset based on naming patterns.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas.DataFrame\n",
    "        Original dataset.\n",
    "\n",
    "    Returns:\n",
    "    - cleaned_df: pandas.DataFrame\n",
    "        Dataset with suspected misclassified rows removed.\n",
    "\n",
    "    This function uses the rule-based flagging logic to detect and exclude entries\n",
    "    that appear to have incorrect labels.\n",
    "    \"\"\"\n",
    "    mismatched_df, _ = flag_misclassified_entries(df)\n",
    "    \n",
    "    # Remove mismatched entries\n",
    "    cleaned_df = df.drop(mismatched_df.index).reset_index(drop=True)\n",
    "    print(f\"Cleaned dataset size after removing misclassified rows: {len(cleaned_df)}\")\n",
    "\n",
    "    return cleaned_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3471a353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of suspected misclassified rows: 84\n",
      "Number of suspected misclassified rows: 84\n",
      "Cleaned dataset size after removing misclassified rows: 4436\n"
     ]
    }
   ],
   "source": [
    "# get the label patterns\n",
    "label_patterns = get_label_patterns()\n",
    "# flag the missclassified entries and print the number (check its not too high)\n",
    "mismatched_df, num_mismatches = flag_misclassified_entries(df)\n",
    "# happy it is not too many, so remove the bad ones\n",
    "df = clean_misclassified_entries(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6680cf3d",
   "metadata": {},
   "source": [
    "## Remove doubled prefixes for names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfe2b3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_double_prefixes(df):\n",
    "    \"\"\"\n",
    "    Removes the first two words in 'dirty_name' if both are common prefixes\n",
    "    (e.g., 'Mr Dr Jane Doe' → 'Jane Doe').\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas.DataFrame\n",
    "        Input DataFrame with a 'dirty_name' column (pre-cleaned, lowercase, no punctuation).\n",
    "\n",
    "    Returns:\n",
    "    - df: pandas.DataFrame\n",
    "        DataFrame with modified 'dirty_name' values where double prefixes were removed.\n",
    "\n",
    "    This function targets cases where two known titles/prefixes occur at the beginning of the name.\n",
    "    It uses a defined prefix list and only alters names that start with two such prefixes.\n",
    "    \"\"\"\n",
    "    # Define common person prefixes\n",
    "    prefixes = {'mr', 'mrs', 'ms', 'miss', 'dr', 'prof', 'rev', 'sr'}\n",
    "\n",
    "    def clean_name(name):\n",
    "        # Split name into parts\n",
    "        parts = name.strip().split()\n",
    "\n",
    "        # Check if first two words are both valid prefixes\n",
    "        if len(parts) >= 2 and parts[0] in prefixes and parts[1] in prefixes:\n",
    "            return ' '.join(parts[2:])  # Remove both\n",
    "        return name\n",
    "\n",
    "    df['dirty_name'] = df['dirty_name'].apply(clean_name)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9532ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = remove_double_prefixes(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43ff713",
   "metadata": {},
   "source": [
    "## Count the number of entries for each category and spread of patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1bae86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_all_patterns_by_label(df, pattern_dict):\n",
    "    \"\"\"\n",
    "    Counts how often each pattern from a label-specific pattern dictionary appears\n",
    "    in the corresponding names within each label group, and includes the total number\n",
    "    of entries per group.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas.DataFrame\n",
    "        DataFrame with 'dirty_name' and 'dirty_label' columns.\n",
    "    - pattern_dict: dict\n",
    "        Dictionary where keys are label names (e.g., 'Person', 'Company') and values are\n",
    "        lists of lowercase patterns to match.\n",
    "\n",
    "    Returns:\n",
    "    - results: dict\n",
    "        A nested dictionary where each key is a label, and the value is another dictionary\n",
    "        containing:\n",
    "            - pattern counts (including 'no_pattern')\n",
    "            - 'total_entries': total number of rows for that label\n",
    "\n",
    "    This function gives insight into how many names match each pattern and the pattern\n",
    "    coverage relative to total entries per category.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    for label, patterns in pattern_dict.items():\n",
    "        label_df = df[df['dirty_label'] == label]\n",
    "        total = len(label_df)\n",
    "\n",
    "        pattern_counts = {p: 0 for p in patterns}\n",
    "        pattern_counts['no_pattern'] = 0\n",
    "        pattern_counts['total_entries'] = total\n",
    "\n",
    "        for name in label_df['dirty_name']:\n",
    "            found = False\n",
    "            for p in patterns:\n",
    "                if p in name:\n",
    "                    pattern_counts[p] += 1\n",
    "                    found = True\n",
    "            if not found:\n",
    "                pattern_counts['no_pattern'] += 1\n",
    "\n",
    "        print(f\"\\nPattern match counts for label: '{label}'\")\n",
    "        print(f\"Total entries: {total}\")\n",
    "        for k, v in pattern_counts.items():\n",
    "            if k != 'total_entries':\n",
    "                print(f\"{k}: {v}\")\n",
    "        \n",
    "        results[label] = pattern_counts\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2b5b2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pattern match counts for label: 'Person'\n",
      "Total entries: 3674\n",
      "mr: 364\n",
      "mrs: 171\n",
      "ms: 121\n",
      "miss: 230\n",
      "dr: 372\n",
      "prof: 119\n",
      "rev: 69\n",
      "sr: 55\n",
      "no_pattern: 2383\n",
      "\n",
      "Pattern match counts for label: 'Company'\n",
      "Total entries: 664\n",
      "pty: 96\n",
      "ltd: 128\n",
      "inc: 25\n",
      "cc: 54\n",
      "corp: 25\n",
      "company: 11\n",
      "llc: 15\n",
      "gmbh: 21\n",
      "foundation: 4\n",
      "trust: 18\n",
      "capital: 6\n",
      "group: 12\n",
      "holdings: 4\n",
      "investments: 6\n",
      "no_pattern: 348\n",
      "\n",
      "Pattern match counts for label: 'University'\n",
      "Total entries: 98\n",
      "university: 58\n",
      "college: 14\n",
      "institute: 2\n",
      "politecnico: 2\n",
      "instituto: 3\n",
      "universidad: 15\n",
      "universidade: 2\n",
      "universite: 2\n",
      "no_pattern: 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Person': {'mr': 364,\n",
       "  'mrs': 171,\n",
       "  'ms': 121,\n",
       "  'miss': 230,\n",
       "  'dr': 372,\n",
       "  'prof': 119,\n",
       "  'rev': 69,\n",
       "  'sr': 55,\n",
       "  'no_pattern': 2383,\n",
       "  'total_entries': 3674},\n",
       " 'Company': {'pty': 96,\n",
       "  'ltd': 128,\n",
       "  'inc': 25,\n",
       "  'cc': 54,\n",
       "  'corp': 25,\n",
       "  'company': 11,\n",
       "  'llc': 15,\n",
       "  'gmbh': 21,\n",
       "  'foundation': 4,\n",
       "  'trust': 18,\n",
       "  'capital': 6,\n",
       "  'group': 12,\n",
       "  'holdings': 4,\n",
       "  'investments': 6,\n",
       "  'no_pattern': 348,\n",
       "  'total_entries': 664},\n",
       " 'University': {'university': 58,\n",
       "  'college': 14,\n",
       "  'institute': 2,\n",
       "  'politecnico': 2,\n",
       "  'instituto': 3,\n",
       "  'universidad': 15,\n",
       "  'universidade': 2,\n",
       "  'universite': 2,\n",
       "  'no_pattern': 6,\n",
       "  'total_entries': 98}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_all_patterns_by_label(df, get_label_patterns())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7679aa5c",
   "metadata": {},
   "source": [
    "Suggested augmentation is add common words at random during training for even split of them.\n",
    "Also need to ensure data split is even when training. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf13bdc",
   "metadata": {},
   "source": [
    "# Data split and augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4fd62f",
   "metadata": {},
   "source": [
    "## split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c805b824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_train_val_split(df, val_frac=0.1, random_state=42):\n",
    "    \"\"\"\n",
    "    Splits a DataFrame into training and validation sets with stratified sampling,\n",
    "    ensuring the validation set contains val_frac proportion of each label class.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas.DataFrame\n",
    "        DataFrame containing 'dirty_name' and 'dirty_label' columns.\n",
    "    - val_frac: float (default=0.1)\n",
    "        Proportion of each class to include in the validation set.\n",
    "    - random_state: int\n",
    "        Seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "    - train_df: pandas.DataFrame\n",
    "        Training set.\n",
    "    - val_df: pandas.DataFrame\n",
    "        Validation set with stratified class proportions.\n",
    "\n",
    "    This function ensures that the split respects class distribution, which is\n",
    "    essential for fair model evaluation when data is imbalanced.\n",
    "    \"\"\"\n",
    "    train_df, val_df = train_test_split(\n",
    "        df,\n",
    "        test_size=val_frac,\n",
    "        stratify=df['dirty_label'],\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # Print split counts for verification\n",
    "    print(\"Split summary:\")\n",
    "    print(\"Train set:\")\n",
    "    print(train_df['dirty_label'].value_counts())\n",
    "    print(\"\\nValidation set:\")\n",
    "    print(val_df['dirty_label'].value_counts())\n",
    "\n",
    "    return train_df.reset_index(drop=True), val_df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f0bf97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split summary:\n",
      "Train set:\n",
      "dirty_label\n",
      "Person        3306\n",
      "Company        598\n",
      "University      88\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Validation set:\n",
      "dirty_label\n",
      "Person        368\n",
      "Company        66\n",
      "University     10\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = stratified_train_val_split(df, val_frac=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57827bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dirty_name</th>\n",
       "      <th>dirty_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mitchell claw</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mrs takalani le roux</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>meline bermingham</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sr julie moland</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>united insurance brokers ltd</td>\n",
       "      <td>Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dr charmaine masilela</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kagiso van eeden</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>osten marikhin</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rev derek robertson</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>meedoo  tazz latz jv co</td>\n",
       "      <td>Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>barend mahlangu</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>carlos sherborne</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rolando adriaens</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>fallen leaves property dev co pl</td>\n",
       "      <td>Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>miss personal simelane</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>rhyzio  gabtype devify llc</td>\n",
       "      <td>Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cora keddie</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>christian hawkswood</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>liza trudgeon</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>eastern mennonite university</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>timmy rendle</td>\n",
       "      <td>Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>seamus hutchin</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>gerti pesek</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>prof prudence butler</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>current ship builders cc</td>\n",
       "      <td>Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>nomi compford</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>frans manuel</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>miss oceanne heisham</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>aigneis stubbin</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>stormy smye</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>sr rosabella bulfoy</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ashely maffioni</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>bjorn rattry</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>omba  eamia browsebug  co</td>\n",
       "      <td>Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>urban matzke</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>lorraine msomi</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>yvonne smit</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>imibono fuels</td>\n",
       "      <td>Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>mada hammerstone</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>munmro tompkins</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>tommie border</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>thomas king</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>allan kunene</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>lincoln university missouri</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>devpoint  skyvu oyondu midel lp</td>\n",
       "      <td>Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>daron creyke</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>gilberta drewes</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>sifiso jansen van vuuren</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>kissiah ricioppo</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>sigismond larkins</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          dirty_name dirty_label\n",
       "0                      mitchell claw      Person\n",
       "1               mrs takalani le roux      Person\n",
       "2                  meline bermingham      Person\n",
       "3                    sr julie moland      Person\n",
       "4       united insurance brokers ltd     Company\n",
       "5              dr charmaine masilela      Person\n",
       "6                   kagiso van eeden      Person\n",
       "7                     osten marikhin      Person\n",
       "8                rev derek robertson      Person\n",
       "9            meedoo  tazz latz jv co     Company\n",
       "10                   barend mahlangu      Person\n",
       "11                  carlos sherborne      Person\n",
       "12                  rolando adriaens      Person\n",
       "13  fallen leaves property dev co pl     Company\n",
       "14            miss personal simelane      Person\n",
       "15        rhyzio  gabtype devify llc     Company\n",
       "16                       cora keddie      Person\n",
       "17               christian hawkswood      Person\n",
       "18                     liza trudgeon      Person\n",
       "19      eastern mennonite university  University\n",
       "20                      timmy rendle     Company\n",
       "21                    seamus hutchin      Person\n",
       "22                       gerti pesek      Person\n",
       "23              prof prudence butler      Person\n",
       "24          current ship builders cc     Company\n",
       "25                     nomi compford      Person\n",
       "26                      frans manuel      Person\n",
       "27              miss oceanne heisham      Person\n",
       "28                   aigneis stubbin      Person\n",
       "29                       stormy smye      Person\n",
       "30               sr rosabella bulfoy      Person\n",
       "31                   ashely maffioni      Person\n",
       "32                      bjorn rattry      Person\n",
       "33         omba  eamia browsebug  co     Company\n",
       "34                      urban matzke      Person\n",
       "35                    lorraine msomi      Person\n",
       "36                       yvonne smit      Person\n",
       "37                     imibono fuels     Company\n",
       "38                  mada hammerstone      Person\n",
       "39                   munmro tompkins      Person\n",
       "40                     tommie border      Person\n",
       "41                       thomas king      Person\n",
       "42                      allan kunene      Person\n",
       "43       lincoln university missouri  University\n",
       "44   devpoint  skyvu oyondu midel lp     Company\n",
       "45                      daron creyke      Person\n",
       "46                   gilberta drewes      Person\n",
       "47          sifiso jansen van vuuren      Person\n",
       "48                  kissiah ricioppo      Person\n",
       "49                 sigismond larkins      Person"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d633894a",
   "metadata": {},
   "source": [
    "## Augment data to give a more even and realistic mix of patterns for training augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a261545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reassign_random_pattern_in_place(df, pattern_dict, seed=42):\n",
    "    \"\"\"\n",
    "    Removes all label-specific patterns from each name, then re-adds one random\n",
    "    pattern (or none) at the original position of a matched pattern. If no pattern was\n",
    "    present, inserts at the beginning for 'Person' and end for 'Company' or 'University'.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas.DataFrame\n",
    "        DataFrame with 'dirty_name' and 'dirty_label' columns.\n",
    "    - pattern_dict: dict\n",
    "        Dictionary of label -> list of patterns.\n",
    "    - seed: int\n",
    "        Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "    - updated_df: pandas.DataFrame\n",
    "        DataFrame with modified 'dirty_name' values.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    updated_names = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        name = row['dirty_name']\n",
    "        label = row['dirty_label']\n",
    "        patterns = pattern_dict.get(label, [])\n",
    "\n",
    "        # Find all pattern matches and track first position\n",
    "        first_match_index = None\n",
    "        name_lower = name.lower()\n",
    "        for pat in patterns:\n",
    "            match = re.search(r'\\b' + re.escape(pat) + r'\\b', name_lower)\n",
    "            if match and first_match_index is None:\n",
    "                first_match_index = match.start()\n",
    "\n",
    "        # Remove all occurrences of patterns\n",
    "        for pat in patterns:\n",
    "            name = re.sub(r'\\b' + re.escape(pat) + r'\\b', '', name, flags=re.IGNORECASE)\n",
    "\n",
    "        # Clean up whitespace\n",
    "        name = re.sub(r'\\s+', ' ', name).strip()\n",
    "\n",
    "        # Choose random pattern to reinsert (or none)\n",
    "        chosen_pattern = random.choice(patterns + [None])\n",
    "\n",
    "        if chosen_pattern:\n",
    "            name_words = name.split()\n",
    "            if first_match_index is not None:\n",
    "                # Estimate insert position based on original match character index\n",
    "                words_before = name_lower[:first_match_index].split()\n",
    "                insert_pos = len(words_before)\n",
    "                insert_pos = min(insert_pos, len(name_words))  # Bound safety\n",
    "                name_words.insert(insert_pos, chosen_pattern)\n",
    "            else:\n",
    "                # If no match existed, insert front or end by label\n",
    "                if label == 'Person':\n",
    "                    name_words = [chosen_pattern] + name_words\n",
    "                else:\n",
    "                    name_words = name_words + [chosen_pattern]\n",
    "\n",
    "            name = ' '.join(name_words)\n",
    "\n",
    "        updated_names.append(name.strip())\n",
    "\n",
    "    updated_df = df.copy()\n",
    "    updated_df['dirty_name'] = updated_names\n",
    "    return updated_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a689e555",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_adjusted = reassign_random_pattern_in_place(train_df, get_label_patterns())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "abe32384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dirty_name</th>\n",
       "      <th>dirty_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mrs mitchell claw</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mr takalani le roux</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dr meline bermingham</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>miss julie moland</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>united insurance brokers cc</td>\n",
       "      <td>Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ms charmaine masilela</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mrs kagiso van eeden</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>osten marikhin</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mrs derek robertson</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>meedoo tazz latz jv co trust</td>\n",
       "      <td>Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rev barend mahlangu</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mr carlos sherborne</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mr rolando adriaens</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>fallen leaves property dev co pl ltd</td>\n",
       "      <td>Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>miss personal simelane</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>rhyzio gabtype devify cc</td>\n",
       "      <td>Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cora keddie</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mr christian hawkswood</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>liza trudgeon</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>eastern mennonite politecnico</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>timmy rendle group</td>\n",
       "      <td>Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>seamus hutchin</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>rev gerti pesek</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>miss prudence butler</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>current ship builders gmbh</td>\n",
       "      <td>Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>dr nomi compford</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>mr frans manuel</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ms oceanne heisham</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>rev aigneis stubbin</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>prof stormy smye</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>dr rosabella bulfoy</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ms ashely maffioni</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>miss bjorn rattry</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>omba eamia browsebug co holdings</td>\n",
       "      <td>Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>prof urban matzke</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>mrs lorraine msomi</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>mrs yvonne smit</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>imibono fuels llc</td>\n",
       "      <td>Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>mrs mada hammerstone</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>prof munmro tompkins</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>prof tommie border</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>dr thomas king</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>mr allan kunene</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>lincoln universite missouri</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>devpoint skyvu oyondu midel lp foundation</td>\n",
       "      <td>Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>mrs daron creyke</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>rev gilberta drewes</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>mrs sifiso jansen van vuuren</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>kissiah ricioppo</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>dr sigismond larkins</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   dirty_name dirty_label\n",
       "0                           mrs mitchell claw      Person\n",
       "1                         mr takalani le roux      Person\n",
       "2                        dr meline bermingham      Person\n",
       "3                           miss julie moland      Person\n",
       "4                 united insurance brokers cc     Company\n",
       "5                       ms charmaine masilela      Person\n",
       "6                        mrs kagiso van eeden      Person\n",
       "7                              osten marikhin      Person\n",
       "8                         mrs derek robertson      Person\n",
       "9                meedoo tazz latz jv co trust     Company\n",
       "10                        rev barend mahlangu      Person\n",
       "11                        mr carlos sherborne      Person\n",
       "12                        mr rolando adriaens      Person\n",
       "13       fallen leaves property dev co pl ltd     Company\n",
       "14                     miss personal simelane      Person\n",
       "15                   rhyzio gabtype devify cc     Company\n",
       "16                                cora keddie      Person\n",
       "17                     mr christian hawkswood      Person\n",
       "18                              liza trudgeon      Person\n",
       "19              eastern mennonite politecnico  University\n",
       "20                         timmy rendle group     Company\n",
       "21                             seamus hutchin      Person\n",
       "22                            rev gerti pesek      Person\n",
       "23                       miss prudence butler      Person\n",
       "24                 current ship builders gmbh     Company\n",
       "25                           dr nomi compford      Person\n",
       "26                            mr frans manuel      Person\n",
       "27                         ms oceanne heisham      Person\n",
       "28                        rev aigneis stubbin      Person\n",
       "29                           prof stormy smye      Person\n",
       "30                        dr rosabella bulfoy      Person\n",
       "31                         ms ashely maffioni      Person\n",
       "32                          miss bjorn rattry      Person\n",
       "33           omba eamia browsebug co holdings     Company\n",
       "34                          prof urban matzke      Person\n",
       "35                         mrs lorraine msomi      Person\n",
       "36                            mrs yvonne smit      Person\n",
       "37                          imibono fuels llc     Company\n",
       "38                       mrs mada hammerstone      Person\n",
       "39                       prof munmro tompkins      Person\n",
       "40                         prof tommie border      Person\n",
       "41                             dr thomas king      Person\n",
       "42                            mr allan kunene      Person\n",
       "43                lincoln universite missouri  University\n",
       "44  devpoint skyvu oyondu midel lp foundation     Company\n",
       "45                           mrs daron creyke      Person\n",
       "46                        rev gilberta drewes      Person\n",
       "47               mrs sifiso jansen van vuuren      Person\n",
       "48                           kissiah ricioppo      Person\n",
       "49                       dr sigismond larkins      Person"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_adjusted.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f0da45",
   "metadata": {},
   "source": [
    "## Augment data randomly with character or entry noise. Augment each entry only once (dataset should double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ea28715c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove some entries from the person category\n",
    "def remove_person_examples(train_df, percentage, seed=42):\n",
    "    \"\"\"\n",
    "    Removes a specified percentage of rows from the 'Person' category in the training dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - train_df: pandas.DataFrame\n",
    "        Training dataset with a 'dirty_label' column.\n",
    "    - percentage: float\n",
    "        Percentage of 'Person' rows to remove (e.g., 0.3 for 30%).\n",
    "    - seed: int\n",
    "        Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "    - reduced_df: pandas.DataFrame\n",
    "        Training dataset with specified portion of 'Person' entries removed.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    assert 0 <= percentage <= 1, \"Percentage must be between 0 and 1\"\n",
    "\n",
    "    person_df = train_df[train_df['dirty_label'] == 'Person']\n",
    "    non_person_df = train_df[train_df['dirty_label'] != 'Person']\n",
    "\n",
    "    # Determine how many to keep\n",
    "    keep_count = int(len(person_df) * (1 - percentage))\n",
    "    reduced_person_df = person_df.sample(n=keep_count, random_state=seed)\n",
    "\n",
    "    # Combine and shuffle\n",
    "    reduced_df = pd.concat([reduced_person_df, non_person_df], ignore_index=True)\n",
    "    reduced_df = reduced_df.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "    return reduced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1a6d5b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df = remove_person_examples(train_df_adjusted, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "fb8ab774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1347, 2)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9323ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation for all categories\n",
    "# def augment_dataset_with_noise(df, seed=42):\n",
    "#     \"\"\"\n",
    "#     Augments the dataset by duplicating each entry once and applying one of two types\n",
    "#     of random noise to the name:\n",
    "#       1. Insert/remove a space or swap two adjacent characters.\n",
    "#       2. Slightly altered duplicate version with same label.\n",
    "\n",
    "#     Parameters:\n",
    "#     - df: pandas.DataFrame\n",
    "#         DataFrame containing 'dirty_name' and 'dirty_label' columns.\n",
    "#     - seed: int\n",
    "#         Random seed for reproducibility.\n",
    "\n",
    "#     Returns:\n",
    "#     - augmented_df: pandas.DataFrame\n",
    "#         New DataFrame with both original and augmented examples (2x the size).\n",
    "#     \"\"\"\n",
    "#     random.seed(seed)\n",
    "#     augmented_rows = []\n",
    "\n",
    "#     def add_character_noise(name):\n",
    "#         \"\"\"Applies one of three noise types to the string: insert space, remove space, or swap characters.\"\"\"\n",
    "#         if len(name) < 2:\n",
    "#             return name\n",
    "\n",
    "#         choice = random.choice(['insert_space', 'remove_space', 'swap_chars'])\n",
    "#         chars = list(name)\n",
    "\n",
    "#         if choice == 'insert_space':\n",
    "#             idx = random.randint(1, len(chars) - 1)\n",
    "#             return name[:idx] + ' ' + name[idx:]\n",
    "#         elif choice == 'remove_space':\n",
    "#             if ' ' in name:\n",
    "#                 idx = name.index(' ')\n",
    "#                 return name[:idx] + name[idx+1:]\n",
    "#             else:\n",
    "#                 return name\n",
    "#         elif choice == 'swap_chars':\n",
    "#             idx = random.randint(0, len(chars) - 2)\n",
    "#             chars[idx], chars[idx+1] = chars[idx+1], chars[idx]\n",
    "#             return ''.join(chars)\n",
    "\n",
    "#     for _, row in df.iterrows():\n",
    "#         name = row['dirty_name']\n",
    "#         label = row['dirty_label']\n",
    "\n",
    "#         augmented_name = add_character_noise(name)  # Apply noise\n",
    "#         augmented_rows.append({\n",
    "#             'dirty_name': augmented_name,\n",
    "#             'dirty_label': label\n",
    "#         })\n",
    "\n",
    "#     # Combine original and augmented\n",
    "#     df_aug = pd.DataFrame(augmented_rows)\n",
    "#     augmented_df = pd.concat([df, df_aug], ignore_index=True)\n",
    "#     return augmented_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a2378c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation with specific categories\n",
    "def augment_dataset_with_noise(df, seed=42):\n",
    "    \"\"\"\n",
    "    Augments the dataset by duplicating entries from 'Company' and 'University' classes,\n",
    "    applying character-level noise:\n",
    "      - 'University': 10 augmentations per original\n",
    "      - 'Company': 3 augmentations per original\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas.DataFrame\n",
    "        DataFrame containing 'dirty_name' and 'dirty_label' columns.\n",
    "    - seed: int\n",
    "        Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "    - augmented_df: pandas.DataFrame\n",
    "        DataFrame with original and augmented entries.\n",
    "    \"\"\"\n",
    "\n",
    "    random.seed(seed)\n",
    "    augmented_rows = []\n",
    "\n",
    "    def add_character_noise(name):\n",
    "        \"\"\"Applies one of three noise types to the string: insert space, remove space, or swap characters.\"\"\"\n",
    "        if len(name) < 2:\n",
    "            return name\n",
    "\n",
    "        choice = random.choice(['insert_space', 'remove_space', 'swap_chars'])\n",
    "        chars = list(name)\n",
    "\n",
    "        if choice == 'insert_space':\n",
    "            idx = random.randint(1, len(chars) - 1)\n",
    "            return name[:idx] + ' ' + name[idx:]\n",
    "        elif choice == 'remove_space':\n",
    "            if ' ' in name:\n",
    "                idx = name.index(' ')\n",
    "                return name[:idx] + name[idx+1:]\n",
    "            else:\n",
    "                return name\n",
    "        elif choice == 'swap_chars':\n",
    "            idx = random.randint(0, len(chars) - 2)\n",
    "            chars[idx], chars[idx+1] = chars[idx+1], chars[idx]\n",
    "            return ''.join(chars)\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        name = row['dirty_name']\n",
    "        label = row['dirty_label']\n",
    "\n",
    "        if label == 'University':\n",
    "            for _ in range(6):\n",
    "                augmented_name = add_character_noise(name)\n",
    "                augmented_rows.append({\n",
    "                    'dirty_name': augmented_name,\n",
    "                    'dirty_label': label\n",
    "                })\n",
    "        # elif label == 'Company':\n",
    "        #     for _ in range(2):\n",
    "        #         augmented_name = add_character_noise(name)\n",
    "        #         augmented_rows.append({\n",
    "        #             'dirty_name': augmented_name,\n",
    "        #             'dirty_label': label\n",
    "        #         })\n",
    "\n",
    "    df_aug = pd.DataFrame(augmented_rows)\n",
    "    augmented_df = pd.concat([df, df_aug], ignore_index=True)\n",
    "    return augmented_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1dfd1dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_train_df = augment_dataset_with_noise(reduced_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "12e8e114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmented_train_df = reduced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ff27edea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmented_train_df = augment_dataset_with_noise(train_df_adjusted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "963ea1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_train_df = reassign_random_pattern_in_place(augmented_train_df, get_label_patterns())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9ae074b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1875, 2)\n"
     ]
    }
   ],
   "source": [
    "print(augmented_train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d4a845ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dirty_name</th>\n",
       "      <th>dirty_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thoughtbeat llp capital</td>\n",
       "      <td>Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>livetube geba ltd</td>\n",
       "      <td>Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mr angelique ivashchenko</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>peernet global bw group</td>\n",
       "      <td>Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dr tshepiso manamela</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>keeley gabbidon cc</td>\n",
       "      <td>Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>castelo branco politecnico</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ms hannie woollam</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>college of kashmir</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bird lifsey</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>oyoba digitube topiczoom ltd</td>\n",
       "      <td>Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fikile gounden trust</td>\n",
       "      <td>Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rodney eliez llc</td>\n",
       "      <td>Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>skinder partnership pty</td>\n",
       "      <td>Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>quatz babbleset fd pty</td>\n",
       "      <td>Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>mrs eloise arran</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>politecnico san francisco xavier de chuquisaca</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>miss william engelbrecht</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>aila tenpenny</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>mr loren gasking</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>alfred pretorius</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>miss munmro tompkins</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>cassandra hamp group</td>\n",
       "      <td>Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>tildy robet</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>rev nessi mcleoid</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>miss amelia biford</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>park gateway airport pl gmbh</td>\n",
       "      <td>Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>zooxo trust</td>\n",
       "      <td>Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>trudy mungan corp</td>\n",
       "      <td>Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>amelie vail holdings</td>\n",
       "      <td>Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>mr nonkululeko mahlangu</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ms pieter ntombela</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>rev kabelo barnes</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>prof janet kotze</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>dr timothy ally</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>zoomzone skippad zoomlounge wikibox pl inc</td>\n",
       "      <td>Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>miss thandeka alberts</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>geba linkbridge as holdings</td>\n",
       "      <td>Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>prof aurelie jemmison</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>yacero oyoba unltd ltd</td>\n",
       "      <td>Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>browsedrive unlimited ltd</td>\n",
       "      <td>Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>rev brett whithalgh</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>mrs kennie wincom</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>prof arnold burger</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>youbridge gabspot investments</td>\n",
       "      <td>Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>prof neilla briggdale</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>dr andries mtshali</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>mr heinrich nkabinde</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>sr lesego dlamini</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>nhlanhla george</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        dirty_name dirty_label\n",
       "0                          thoughtbeat llp capital     Company\n",
       "1                                livetube geba ltd     Company\n",
       "2                         mr angelique ivashchenko      Person\n",
       "3                          peernet global bw group     Company\n",
       "4                             dr tshepiso manamela      Person\n",
       "5                               keeley gabbidon cc     Company\n",
       "6                       castelo branco politecnico  University\n",
       "7                                ms hannie woollam      Person\n",
       "8                               college of kashmir  University\n",
       "9                                      bird lifsey      Person\n",
       "10                    oyoba digitube topiczoom ltd     Company\n",
       "11                            fikile gounden trust     Company\n",
       "12                                rodney eliez llc     Company\n",
       "13                         skinder partnership pty     Company\n",
       "14                          quatz babbleset fd pty     Company\n",
       "15                                mrs eloise arran      Person\n",
       "16  politecnico san francisco xavier de chuquisaca  University\n",
       "17                        miss william engelbrecht      Person\n",
       "18                                   aila tenpenny      Person\n",
       "19                                mr loren gasking      Person\n",
       "20                                alfred pretorius      Person\n",
       "21                            miss munmro tompkins      Person\n",
       "22                            cassandra hamp group     Company\n",
       "23                                     tildy robet      Person\n",
       "24                               rev nessi mcleoid      Person\n",
       "25                              miss amelia biford      Person\n",
       "26                    park gateway airport pl gmbh     Company\n",
       "27                                     zooxo trust     Company\n",
       "28                               trudy mungan corp     Company\n",
       "29                            amelie vail holdings     Company\n",
       "30                         mr nonkululeko mahlangu      Person\n",
       "31                              ms pieter ntombela      Person\n",
       "32                               rev kabelo barnes      Person\n",
       "33                                prof janet kotze      Person\n",
       "34                                 dr timothy ally      Person\n",
       "35      zoomzone skippad zoomlounge wikibox pl inc     Company\n",
       "36                           miss thandeka alberts      Person\n",
       "37                     geba linkbridge as holdings     Company\n",
       "38                           prof aurelie jemmison      Person\n",
       "39                          yacero oyoba unltd ltd     Company\n",
       "40                       browsedrive unlimited ltd     Company\n",
       "41                             rev brett whithalgh      Person\n",
       "42                               mrs kennie wincom      Person\n",
       "43                              prof arnold burger      Person\n",
       "44                   youbridge gabspot investments     Company\n",
       "45                           prof neilla briggdale      Person\n",
       "46                              dr andries mtshali      Person\n",
       "47                            mr heinrich nkabinde      Person\n",
       "48                               sr lesego dlamini      Person\n",
       "49                                 nhlanhla george      Person"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_train_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "f8cf9d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dirty_name</th>\n",
       "      <th>dirty_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>brunel polit ecnico uxbridge instituto</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1826</th>\n",
       "      <td>brunel politencico uxbridge universidade</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1827</th>\n",
       "      <td>luther univresity university</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1828</th>\n",
       "      <td>luther univ ersity universidad</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1829</th>\n",
       "      <td>luther univers ity politecnico</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1830</th>\n",
       "      <td>lutheruniversity universidade</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1831</th>\n",
       "      <td>luther univers ity institute</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1832</th>\n",
       "      <td>lutheruniversity college</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1833</th>\n",
       "      <td>xiangtan instiutte</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1834</th>\n",
       "      <td>xiantgan universidad</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1835</th>\n",
       "      <td>xiangtaninstitute college</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1836</th>\n",
       "      <td>xiangtan institut e</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1837</th>\n",
       "      <td>xiangtani nstitute</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1838</th>\n",
       "      <td>xiangtan instittue</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1839</th>\n",
       "      <td>collegeof the visayas</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1840</th>\n",
       "      <td>collegeof the visayas</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1841</th>\n",
       "      <td>university of the visyaas</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1842</th>\n",
       "      <td>collegeof the visayas universidade</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1843</th>\n",
       "      <td>collegeof the visayas universite</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1844</th>\n",
       "      <td>col lege of the visayas university</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1845</th>\n",
       "      <td>universidadpanamericana de san salvador univer...</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1846</th>\n",
       "      <td>universidadpanamericana de san salvador univer...</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1847</th>\n",
       "      <td>instituto panamericana de sa n salvador</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1848</th>\n",
       "      <td>university panamericanad e san salvador</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1849</th>\n",
       "      <td>universidadpanamericana de san salvador univer...</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1850</th>\n",
       "      <td>college panamericana de san salvador</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851</th>\n",
       "      <td>institutotecnologica de pereira universidad</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1852</th>\n",
       "      <td>politecnico tecnol ogica de pereira</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1853</th>\n",
       "      <td>college te cnologica de pereira</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1854</th>\n",
       "      <td>institutotecnologica de pereira universidad</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1855</th>\n",
       "      <td>institutotecnologica de pereira institute</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1856</th>\n",
       "      <td>institutotecnologica de pereira university</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1857</th>\n",
       "      <td>american universidad of tiarna</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1858</th>\n",
       "      <td>americancollege of tirana</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1859</th>\n",
       "      <td>maerican universidad of tirana</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>americna institute of tirana</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861</th>\n",
       "      <td>american universite of tirana</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862</th>\n",
       "      <td>american collgee of tirana universite</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1863</th>\n",
       "      <td>yerevanstate medical institute</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>yerevan state medical intsituto institute</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1865</th>\n",
       "      <td>yerevan state medical i nstituto college</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1866</th>\n",
       "      <td>yerevanstate medical universite</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867</th>\n",
       "      <td>yerevan state medical nistituto university</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1868</th>\n",
       "      <td>yerevanstate medical instituto</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1869</th>\n",
       "      <td>ictuniversidad politecnico</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1870</th>\n",
       "      <td>ic t university</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1871</th>\n",
       "      <td>ictuniversidad politecnico</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1872</th>\n",
       "      <td>ict uni versidad university</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1873</th>\n",
       "      <td>ictu niversidad universidad</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874</th>\n",
       "      <td>ictuniversidad instituto</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             dirty_name dirty_label\n",
       "1825             brunel polit ecnico uxbridge instituto  University\n",
       "1826           brunel politencico uxbridge universidade  University\n",
       "1827                       luther univresity university  University\n",
       "1828                     luther univ ersity universidad  University\n",
       "1829                     luther univers ity politecnico  University\n",
       "1830                      lutheruniversity universidade  University\n",
       "1831                       luther univers ity institute  University\n",
       "1832                           lutheruniversity college  University\n",
       "1833                                 xiangtan instiutte  University\n",
       "1834                               xiantgan universidad  University\n",
       "1835                          xiangtaninstitute college  University\n",
       "1836                                xiangtan institut e  University\n",
       "1837                                 xiangtani nstitute  University\n",
       "1838                                 xiangtan instittue  University\n",
       "1839                              collegeof the visayas  University\n",
       "1840                              collegeof the visayas  University\n",
       "1841                          university of the visyaas  University\n",
       "1842                 collegeof the visayas universidade  University\n",
       "1843                   collegeof the visayas universite  University\n",
       "1844                 col lege of the visayas university  University\n",
       "1845  universidadpanamericana de san salvador univer...  University\n",
       "1846  universidadpanamericana de san salvador univer...  University\n",
       "1847            instituto panamericana de sa n salvador  University\n",
       "1848            university panamericanad e san salvador  University\n",
       "1849  universidadpanamericana de san salvador univer...  University\n",
       "1850               college panamericana de san salvador  University\n",
       "1851        institutotecnologica de pereira universidad  University\n",
       "1852                politecnico tecnol ogica de pereira  University\n",
       "1853                    college te cnologica de pereira  University\n",
       "1854        institutotecnologica de pereira universidad  University\n",
       "1855          institutotecnologica de pereira institute  University\n",
       "1856         institutotecnologica de pereira university  University\n",
       "1857                     american universidad of tiarna  University\n",
       "1858                          americancollege of tirana  University\n",
       "1859                     maerican universidad of tirana  University\n",
       "1860                       americna institute of tirana  University\n",
       "1861                      american universite of tirana  University\n",
       "1862              american collgee of tirana universite  University\n",
       "1863                     yerevanstate medical institute  University\n",
       "1864          yerevan state medical intsituto institute  University\n",
       "1865           yerevan state medical i nstituto college  University\n",
       "1866                    yerevanstate medical universite  University\n",
       "1867         yerevan state medical nistituto university  University\n",
       "1868                     yerevanstate medical instituto  University\n",
       "1869                         ictuniversidad politecnico  University\n",
       "1870                                    ic t university  University\n",
       "1871                         ictuniversidad politecnico  University\n",
       "1872                        ict uni versidad university  University\n",
       "1873                        ictu niversidad universidad  University\n",
       "1874                           ictuniversidad instituto  University"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_train_df.tail(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ae34fd",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "2e80607a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_logreg_model(train_df, test_df, model_path='best_logreg_model.joblib'):\n",
    "    \"\"\"\n",
    "    Trains a Logistic Regression model with TF-IDF features and evaluates on the test set.\n",
    "    Reports metrics every 25 iterations and saves separate plots for each metric, per-class metrics,\n",
    "    and a confusion matrix plot.\n",
    "\n",
    "    Parameters:\n",
    "    - train_df: pandas.DataFrame\n",
    "        Training dataset with 'dirty_name' and 'dirty_label' columns.\n",
    "    - test_df: pandas.DataFrame\n",
    "        Test dataset with same structure.\n",
    "    - model_path: str\n",
    "        Path to save the best model.\n",
    "\n",
    "    Returns:\n",
    "    - metrics: dict\n",
    "        Dictionary of evaluation metrics (accuracy, recall, F1, confusion matrix).\n",
    "    \"\"\"\n",
    "    X_train = train_df['dirty_name']\n",
    "    y_train = train_df['dirty_label']\n",
    "    X_test = test_df['dirty_name']\n",
    "    y_test = test_df['dirty_label']\n",
    "\n",
    "    # Vectoriser\n",
    "    vectoriser = TfidfVectorizer(ngram_range=(2, 5), max_features=3000)\n",
    "    X_train_tfidf = vectoriser.fit_transform(X_train)\n",
    "    X_test_tfidf = vectoriser.transform(X_test)\n",
    "\n",
    "    # Model with warm_start to track progress\n",
    "    model = LogisticRegression(\n",
    "        C=1,\n",
    "        class_weight='balanced',\n",
    "        max_iter=25,\n",
    "        warm_start=True,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    max_iter = 100\n",
    "    steps = max_iter // 25\n",
    "    all_metrics = {'loss': [], 'accuracy': [], 'recall': [], 'f1': []}\n",
    "\n",
    "    for i in range(steps):\n",
    "        model.max_iter += 25\n",
    "        model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_test_tfidf)\n",
    "        y_proba = model.predict_proba(X_test_tfidf)\n",
    "\n",
    "        loss = log_loss(y_test, y_proba)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred, average='macro')\n",
    "        f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "        all_metrics['loss'].append(loss)\n",
    "        all_metrics['accuracy'].append(acc)\n",
    "        all_metrics['recall'].append(recall)\n",
    "        all_metrics['f1'].append(f1)\n",
    "\n",
    "        print(f\"After {model.max_iter} iterations:\")\n",
    "        print(f\"  Loss: {loss:.4f}, Accuracy: {acc:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\\n\")\n",
    "\n",
    "    # Final predictions\n",
    "    y_pred_final = model.predict(X_test_tfidf)\n",
    "    cm = confusion_matrix(y_test, y_pred_final, labels=np.unique(y_test))\n",
    "    report = classification_report(y_test, y_pred_final, output_dict=True)\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "\n",
    "    # Save model and vectoriser in a pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', vectoriser),\n",
    "        ('clf', model)\n",
    "    ])\n",
    "    dump(pipeline, model_path)\n",
    "\n",
    "    # Save plots directory\n",
    "    plot_dir = os.path.splitext(model_path)[0] + \"_plots\"\n",
    "    os.makedirs(plot_dir, exist_ok=True)\n",
    "    x_ticks = [(i+1)*25 for i in range(steps)]\n",
    "\n",
    "    # Save individual metric plots\n",
    "    for metric in all_metrics:\n",
    "        plt.figure()\n",
    "        plt.plot(x_ticks, all_metrics[metric], marker='o')\n",
    "        plt.title(f'{metric.capitalize()} over Iterations')\n",
    "        plt.xlabel('Iterations')\n",
    "        plt.ylabel(metric.capitalize())\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plot_path = os.path.join(plot_dir, f\"{metric}_plot.png\")\n",
    "        plt.savefig(plot_path)\n",
    "        plt.close()\n",
    "\n",
    "    # Save per-class metrics plot\n",
    "    for class_label in report_df.index[:-3]:  # Exclude avg/total rows\n",
    "        plt.figure()\n",
    "        for metric in ['precision', 'recall', 'f1-score']:\n",
    "            plt.bar(metric, report_df.loc[class_label, metric])\n",
    "        plt.ylim(0, 1)\n",
    "        plt.title(f'Performance for class: {class_label}')\n",
    "        plt.tight_layout()\n",
    "        plot_path = os.path.join(plot_dir, f\"{class_label}_metrics.png\")\n",
    "        plt.savefig(plot_path)\n",
    "        plt.close()\n",
    "\n",
    "    # Save confusion matrix plot\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', xticklabels=np.unique(y_test), yticklabels=np.unique(y_test), cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix')\n",
    "    cm_path = os.path.join(plot_dir, \"confusion_matrix.png\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(cm_path)\n",
    "    plt.close()\n",
    "\n",
    "    return {\n",
    "        'accuracy': all_metrics['accuracy'][-1],\n",
    "        'recall': all_metrics['recall'][-1],\n",
    "        'f1_score': all_metrics['f1'][-1],\n",
    "        'confusion_matrix': cm\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d7150cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 50 iterations:\n",
      "  Loss: 0.9511, Accuracy: 0.8604, Recall: 0.5737, F1 Score: 0.6295\n",
      "\n",
      "After 75 iterations:\n",
      "  Loss: 0.9511, Accuracy: 0.8604, Recall: 0.5737, F1 Score: 0.6295\n",
      "\n",
      "After 100 iterations:\n",
      "  Loss: 0.9511, Accuracy: 0.8604, Recall: 0.5737, F1 Score: 0.6295\n",
      "\n",
      "After 125 iterations:\n",
      "  Loss: 0.9511, Accuracy: 0.8604, Recall: 0.5737, F1 Score: 0.6295\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = train_and_evaluate_logreg_model(augmented_train_df, test_df, model_path='best_logreg_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "100745c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.8581081081081081, 'recall': 0.5686868686868687, 'f1_score': 0.6209774204056441, 'confusion_matrix': array([[  7,  59,   0],\n",
      "       [  0, 368,   0],\n",
      "       [  0,   4,   6]])}\n"
     ]
    }
   ],
   "source": [
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141dc846",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Melio_name_classifier_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
